### PROJETO PIX - KAFKA E RABBITMQ (PUB/SUB)


* `README.md` documentado para GitHub ‚úÖ
* Comandos de teste com `curl` ‚úÖ
* Execu√ß√£o no VSCode ‚úÖ
* (Extra) `docker-compose.yaml` para rodar localmente sem Kubernetes ‚úÖ

---

## üìù `README.md`

```md
# üí≥ PIX Pub/Sub Architecture with Kafka and RabbitMQ

Este projeto implementa uma arquitetura de mensageria para transa√ß√µes PIX simuladas, utilizando **Kafka** e **RabbitMQ** como mecanismos de Pub/Sub. Foi projetado para ambientes Kubernetes via **Minikube** com observabilidade integrada (Prometheus + Grafana + Alertmanager).

---

## üìÅ Estrutura

```

pix-pubsub-architecture/
‚îú‚îÄ‚îÄ api-kafka/             # API Flask que envia eventos para Kafka
‚îú‚îÄ‚îÄ api-rabbitmq/          # API Flask que envia eventos para RabbitMQ
‚îú‚îÄ‚îÄ k8s/                   # Manifests Kubernetes
‚îÇ   ‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îú‚îÄ‚îÄ rabbitmq/
‚îÇ   ‚îú‚îÄ‚îÄ api-kafka/
‚îÇ   ‚îú‚îÄ‚îÄ api-rabbitmq/
‚îÇ   ‚îú‚îÄ‚îÄ ingress/
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md

````

---

## üöÄ Funcionalidade

T√≥picos utilizados no padr√£o de mensageria PIX:

| T√≥pico / Routing Key         | Fun√ß√£o                         |
|-----------------------------|--------------------------------|
| `pix.payment.requested`     | In√≠cio da transa√ß√£o            |
| `pix.payment.validated`     | P√≥s-antifraude                 |
| `pix.payment.settled`       | Liquida√ß√£o confirmada          |
| `pix.notification.sent`     | Notifica√ß√£o enviada            |
| `pix.audit.log`             | Auditoria e rastreabilidade    |

---

## ‚úÖ Pr√©-requisitos

- Minikube
- Helm
- Docker
- Kubectl
- VSCode com extens√£o Kubernetes

---

## ‚öôÔ∏è Build das imagens

```bash
eval $(minikube docker-env)
docker build -t api-kafka:latest ./api-kafka
docker build -t api-rabbitmq:latest ./api-rabbitmq
````

---

## ‚ò∏Ô∏è Deploy no Kubernetes

```bash
minikube start --driver=docker
minikube addons enable ingress

kubectl apply -f k8s/namespaces.yaml
kubectl apply -f k8s/kafka/
kubectl apply -f k8s/rabbitmq/
kubectl apply -f k8s/api-kafka/
kubectl apply -f k8s/api-rabbitmq/
kubectl apply -f k8s/ingress/
kubectl apply -f k8s/monitoring/
```

---

## üåê Acessos

Ver IP:

```bash
minikube ip
```

| Servi√ßo        | Porta       | Exemplo URL                  |
| -------------- | ----------- | ---------------------------- |
| API Kafka      | via ingress | `http://pix.local/kafka`     |
| API RabbitMQ   | via ingress | `http://pix.local/rabbit`    |
| Grafana        | 30300       | `http://<minikube-ip>:30300` |
| Prometheus     | 30090       | `http://<minikube-ip>:30090` |
| Alertmanager   | 30093       | `http://<minikube-ip>:30093` |
| RabbitMQ Panel | 15672       | `http://<minikube-ip>:15672` |

---

## üß™ Testes com `curl`

### Enviar evento Kafka:

```bash
curl -X POST http://pix.local/kafka -H "Content-Type: application/json" -d '{
  "topic": "pix.payment.requested",
  "value": {
    "transactionId": "12345",
    "amount": 100,
    "payer": "alice",
    "receiver": "bob"
  }
}'
```

### Enviar evento RabbitMQ:

```bash
curl -X POST http://pix.local/rabbit -H "Content-Type: application/json" -d '{
  "topic": "pix.notification.sent",
  "value": {
    "transactionId": "12345",
    "status": "notified"
  }
}'
```

---

## üß™ Rodar local com `docker-compose` (opcional)

```yaml
# docker-compose.yaml (adicione na raiz se desejar rodar fora do k8s)
version: '3'
services:
  kafka:
    image: bitnami/kafka:latest
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper

  zookeeper:
    image: bitnami/zookeeper:latest
    ports:
      - "2181:2181"

  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "5672:5672"
      - "15672:15672"

  api-kafka:
    build: ./api-kafka
    ports:
      - "5000:5000"
    depends_on:
      - kafka

  api-rabbitmq:
    build: ./api-rabbitmq
    ports:
      - "5001:5001"
    depends_on:
      - rabbitmq
```

> Para rodar:

```bash
docker-compose up --build
```

---

## ‚úÖ Checklist final

* [x] Kafka com 5 t√≥picos de PIX
* [x] RabbitMQ com Exchange `pix` tipo `topic`
* [x] APIs Flask separadas (Kafka / Rabbit)
* [x] Dockerfiles prontos
* [x] Manifests Kubernetes completos
* [x] Ingress configurado
* [x] Monitoring com Prometheus, Grafana, Alertmanager
* [x] Documenta√ß√£o pronta (este README)


---

## üß© 1. Dashboards Prometheus e Grafana (customizados)

### üìÑ `grafana-datasource.yaml` (configMap opcional via Helm/Grafana Operator)

```yaml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
```

### üìÑ Dashboard JSON (exemplo b√°sico para Kafka e RabbitMQ)

Salve como `grafana-dashboard-kafka-rabbit.json` (recomendo importar via painel):

```json
{
  "title": "PIX PubSub Metrics",
  "panels": [
    {
      "type": "graph",
      "title": "Kafka Request Rate",
      "targets": [
        {
          "expr": "rate(kafka_server_brokertopicmetrics_messages_in_total[1m])",
          "legendFormat": "{{topic}}",
          "refId": "A"
        }
      ]
    },
    {
      "type": "graph",
      "title": "RabbitMQ Message Published",
      "targets": [
        {
          "expr": "rate(rabbitmq_messages_published_total[1m])",
          "legendFormat": "{{queue}}",
          "refId": "B"
        }
      ]
    }
  ]
}
```

> Importe esse JSON manualmente no painel do Grafana (menu lateral ‚Üí Dashboards ‚Üí Import).

---

## ‚öôÔ∏è 2. Scripts utilit√°rios

### üìÑ `scripts/create_kafka_topics.sh`

```bash
#!/bin/bash
NAMESPACE=api-kafka
POD=$(kubectl get pods -n $NAMESPACE -l app=kafka -o jsonpath="{.items[0].metadata.name}")

TOPICS=(
  pix.payment.requested
  pix.payment.validated
  pix.payment.settled
  pix.notification.sent
  pix.audit.log
)

for topic in "${TOPICS[@]}"; do
  echo "Creating topic: $topic"
  kubectl -n $NAMESPACE exec -it $POD -- kafka-topics.sh --create --topic $topic --bootstrap-server localhost:9092 --if-not-exists
done
```

> Execute: `chmod +x scripts/create_kafka_topics.sh && ./scripts/create_kafka_topics.sh`

---

### üìÑ `scripts/health_check.sh`

```bash
#!/bin/bash

echo "Kafka API:"
curl -s -o /dev/null -w "%{http_code}\\n" http://pix.local/kafka

echo "RabbitMQ API:"
curl -s -o /dev/null -w "%{http_code}\\n" http://pix.local/rabbit

echo "Prometheus:"
curl -s -o /dev/null -w "%{http_code}\\n" http://$(minikube ip):30090

echo "Grafana:"
curl -s -o /dev/null -w "%{http_code}\\n" http://$(minikube ip):30300
```

---

## üîê 3. Boas pr√°ticas para produ√ß√£o (checklist resumido)

| Categoria        | A√ß√£o Recomendada                                                   |
| ---------------- | ------------------------------------------------------------------ |
| **Seguran√ßa**    | Adicionar TLS no Ingress e autentica√ß√£o nas APIs                   |
| **Kafka**        | Usar `Kafka SASL` + ACL para autentica√ß√£o e controle               |
| **RabbitMQ**     | Criar usu√°rios com permiss√µes separadas por Exchange               |
| **Logs**         | Incluir `loguru` ou `structlog` nas APIs Flask                     |
| **Tracing**      | OpenTelemetry com Grafana Tempo ou Jaeger                          |
| **Persist√™ncia** | Usar PV/PVC em Kafka/RabbitMQ (n√£o in-memory)                      |
| **CI/CD**        | Criar pipeline GitHub Actions com `docker build` + `kubectl apply` |
| **Auto Scaling** | Adicionar HPA baseado em CPU e fila de mensagens                   |

---

## üìÅ 4. Sugest√£o de organiza√ß√£o final no GitHub

```bash
pix-pubsub-architecture/
‚îú‚îÄ‚îÄ api-kafka/
‚îú‚îÄ‚îÄ api-rabbitmq/
‚îú‚îÄ‚îÄ k8s/
‚îú‚îÄ‚îÄ scripts/                    # <=== novo
‚îÇ   ‚îú‚îÄ‚îÄ create_kafka_topics.sh
‚îÇ   ‚îî‚îÄ‚îÄ health_check.sh
‚îú‚îÄ‚îÄ dashboards/                # <=== novo
‚îÇ   ‚îî‚îÄ‚îÄ grafana-dashboard-kafka-rabbit.json
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

## ‚úÖ Finalizamos!

Voc√™ agora tem uma arquitetura completa, com:

* APIs isoladas para Kafka e RabbitMQ
* Infraestrutura Kubernetes com boas pr√°ticas
* Observabilidade real com Prometheus e Grafana
* Ingress, namespace, build, testes e at√© script de health check


Vou detalhar cada um desses itens para evoluir seu projeto PIX Pub/Sub no Kubernetes.

---

# 1Ô∏è‚É£ CI/CD com GitHub Actions

Vou criar um workflow b√°sico para:

* Buildar as imagens Docker dentro do Minikube (usando docker-in-docker)
* Aplicar os manifests Kubernetes
* Fazer deploy autom√°tico ao push na branch `main`

**`.github/workflows/deploy.yml`**

```yaml
name: CI/CD Pipeline

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Log in to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push api-kafka image
        run: |
          docker build -t ${{ secrets.DOCKER_USERNAME }}/api-kafka:latest ./api-kafka
          docker push ${{ secrets.DOCKER_USERNAME }}/api-kafka:latest

      - name: Build and push api-rabbitmq image
        run: |
          docker build -t ${{ secrets.DOCKER_USERNAME }}/api-rabbitmq:latest ./api-rabbitmq
          docker push ${{ secrets.DOCKER_USERNAME }}/api-rabbitmq:latest

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure kubeconfig
        run: |
          echo "${{ secrets.KUBE_CONFIG_DATA }}" | base64 --decode > $HOME/.kube/config

      - name: Deploy to Kubernetes
        run: |
          kubectl apply -f k8s/namespaces.yaml
          kubectl apply -f k8s/kafka/
          kubectl apply -f k8s/rabbitmq/
          kubectl apply -f k8s/api-kafka/
          kubectl apply -f k8s/api-rabbitmq/
          kubectl apply -f k8s/ingress/
          kubectl apply -f k8s/monitoring/
```

> **Nota:**
>
> * Configure os segredos no GitHub (`DOCKER_USERNAME`, `DOCKER_PASSWORD`, `KUBE_CONFIG_DATA` com o conte√∫do do seu kubeconfig base64).
> * Voc√™ pode usar GitHub Packages ou outro registry se preferir.

---

# 2Ô∏è‚É£ OpenTelemetry (Tracing Distribu√≠do)

### Como adicionar tracing b√°sico nas APIs com OpenTelemetry

Instale libs extras:

```bash
pip install opentelemetry-api opentelemetry-sdk opentelemetry-instrumentation-flask opentelemetry-exporter-otlp
```

### Exemplo de instrumenta√ß√£o em `api-kafka/app.py`

```python
from flask import Flask, request, jsonify
from producer_kafka import publish_event

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace.export import BatchSpanProcessor

app = Flask(__name__)

# Setup OpenTelemetry Tracer
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

otlp_exporter = OTLPSpanExporter(endpoint="http://otel-collector:4317", insecure=True)
span_processor = BatchSpanProcessor(otlp_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

FlaskInstrumentor().instrument_app(app)

@app.route("/pix/kafka", methods=["POST"])
def pix_kafka():
    data = request.json
    topic = data.get("topic", "pix.payment.requested")
    publish_event(topic, data)
    return jsonify({"status": "Event sent to Kafka", "topic": topic}), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

---

### Otel Collector - Kubernetes Manifest (exemplo simples)

`k8s/monitoring/otel-collector.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
        - name: otel-collector
          image: otel/opentelemetry-collector-contrib:latest
          command:
            - "/otelcontribcol"
            - "--config=/conf/otel-collector-config.yaml"
          volumeMounts:
            - name: config-volume
              mountPath: /conf
      volumes:
        - name: config-volume
          configMap:
            name: otel-collector-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: monitoring
data:
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:

    exporters:
      logging:
        logLevel: debug
      prometheus:
        endpoint: "0.0.0.0:8888"

    processors:
      batch:

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [logging]
        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: [prometheus]
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  selector:
    app: otel-collector
  ports:
    - port: 4317
      name: otlp-grpc
    - port: 55681
      name: otlp-http
```

---

# 3Ô∏è‚É£ Recebimento de mensagens (Consumers)

### Exemplo b√°sico consumer Kafka (crie `api-kafka/consumer_kafka.py`)

```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'pix.payment.requested',
    bootstrap_servers='kafka-service:9092',
    auto_offset_reset='earliest',
    group_id='pix-group',
    value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

for message in consumer:
    print(f"Received message: {message.value}")
    # Aqui voc√™ pode processar a mensagem e chamar outras APIs, armazenar logs, etc.
```

---

### Exemplo b√°sico consumer RabbitMQ (`api-rabbitmq/consumer_rabbit.py`)

```python
import pika
import json

def callback(ch, method, properties, body):
    print(f"Received {method.routing_key}: {body}")
    # Aqui voc√™ pode processar a mensagem

connection = pika.BlockingConnection(pika.ConnectionParameters(host='rabbitmq-service'))
channel = connection.channel()
channel.exchange_declare(exchange='pix', exchange_type='topic', durable=True)

result = channel.queue_declare('', exclusive=True)
queue_name = result.method.queue

# Bind para todos os t√≥picos PIX
routing_keys = [
    'pix.payment.requested',
    'pix.payment.validated',
    'pix.payment.settled',
    'pix.notification.sent',
    'pix.audit.log'
]

for key in routing_keys:
    channel.queue_bind(exchange='pix', queue=queue_name, routing_key=key)

channel.basic_consume(queue=queue_name, on_message_callback=callback, auto_ack=True)
print('Waiting for messages...')
channel.start_consuming()
```

---

# 4Ô∏è‚É£ Simulador PIX com mock end-to-end

### Script simples que gera eventos na API Kafka e RabbitMQ

`simulator/send_events.py`

```python
import requests
import time
import random

KAFKA_URL = "http://pix.local/kafka"
RABBIT_URL = "http://pix.local/rabbit"

pix_events = [
    {
        "topic": "pix.payment.requested",
        "value": {"transactionId": "tx123", "amount": 100, "payer": "Alice", "receiver": "Bob"}
    },
    {
        "topic": "pix.payment.validated",
        "value": {"transactionId": "tx123", "status": "validated"}
    },
    {
        "topic": "pix.payment.settled",
        "value": {"transactionId": "tx123", "status": "settled"}
    },
    {
        "topic": "pix.notification.sent",
        "value": {"transactionId": "tx123", "status": "notified"}
    },
    {
        "topic": "pix.audit.log",
        "value": {"transactionId": "tx123", "action": "completed"}
    },
]

def send_event(url, event):
    response = requests.post(url, json=event)
    print(f"Sent to {url}: {response.status_code} - {response.json()}")

if __name__ == "__main__":
    while True:
        event = random.choice(pix_events)
        target = KAFKA_URL if 'payment' in event["topic"] else RABBIT_URL
        send_event(target, event)
        time.sleep(5)
```

---

# Como usar:

1. Suba toda a infra e as APIs no Kubernetes (como nas partes anteriores).
2. Em outro terminal, execute o consumer Kafka:

```bash
kubectl exec -n api-kafka -it deploy/api-kafka -- python consumer_kafka.py
```

3. Execute o consumer RabbitMQ:

```bash
kubectl exec -n api-rabbitmq -it deploy/api-rabbitmq -- python consumer_rabbit.py
```

4. Execute localmente o simulador (precisa do Python com `requests` instalado):

```bash
pip install requests
python simulator/send_events.py
```


## üìå Observa√ß√£o

Este projeto √© uma simula√ß√£o local de arquitetura Pub/Sub para mensageria de transa√ß√µes PIX. Para produ√ß√£o, recomenda-se uso de TLS, autentica√ß√£o Kafka, RabbitMQ HA, observabilidade avan√ßada (OpenTelemetry), logs estruturados e persist√™ncia.

---

## üë®‚Äçüíª Autor

Nelson Walcow
\[SRE | DevOps | Engenharia de Dados | Cloud Specialist]




